"""
Watermarking utilities for voice cloning
Based on: https://github.com/isaiahbjork/csm-voice-cloning
"""

import numpy as np
import soundfile as sf
import librosa
from typing import Optional

def apply_watermark(audio_path: str, output_path: str, 
                   watermark_text: str = "Generated by CSM Voice Cloning",
                   method: str = "metadata") -> str:
    """
    Apply watermark to generated audio
    
    Args:
        audio_path: Path to the input audio file
        output_path: Path to save the watermarked audio
        watermark_text: Text to embed as watermark
        method: Watermarking method ("metadata", "spectral", or "temporal")
        
    Returns:
        Path to the watermarked audio file
    """
    # Load audio
    audio, sr = librosa.load(audio_path, sr=None)
    
    if method == "metadata":
        # Simple metadata watermarking
        _apply_metadata_watermark(audio, sr, output_path, watermark_text)
    elif method == "spectral":
        # Spectral watermarking (subtle frequency domain modification)
        audio = _apply_spectral_watermark(audio, watermark_text)
        sf.write(output_path, audio, sr)
    elif method == "temporal":
        # Temporal watermarking (subtle time domain modification)
        audio = _apply_temporal_watermark(audio, watermark_text)
        sf.write(output_path, audio, sr)
    else:
        raise ValueError(f"Unknown watermarking method: {method}")
    
    print(f"Watermarked audio saved to: {output_path}")
    return output_path

def _apply_metadata_watermark(audio: np.ndarray, sr: int, output_path: str, 
                             watermark_text: str):
    """Apply metadata-based watermarking"""
    # Save with basic metadata (soundfile doesn't support custom metadata directly)
    sf.write(output_path, audio, sr)
    print(f"Metadata watermark applied: {watermark_text}")

def _apply_spectral_watermark(audio: np.ndarray, watermark_text: str) -> np.ndarray:
    """
    Apply spectral watermarking by modifying frequency domain
    
    Args:
        audio: Input audio array
        watermark_text: Text to embed
        
    Returns:
        Watermarked audio array
    """
    # Convert to frequency domain
    stft = librosa.stft(audio)
    magnitude = np.abs(stft)
    phase = np.angle(stft)
    
    # Create a simple watermark pattern based on text hash
    watermark_hash = hash(watermark_text) % 1000
    watermark_pattern = np.sin(np.linspace(0, 2 * np.pi * watermark_hash, magnitude.shape[1]))
    
    # Apply very subtle modifications to magnitude spectrum
    for i in range(magnitude.shape[0]):
        if i % 10 == 0:  # Only modify every 10th frequency bin
            magnitude[i] *= (1 + 0.001 * watermark_pattern)
    
    # Reconstruct audio
    watermarked_stft = magnitude * np.exp(1j * phase)
    watermarked_audio = librosa.istft(watermarked_stft)
    
    return watermarked_audio

def _apply_temporal_watermark(audio: np.ndarray, watermark_text: str) -> np.ndarray:
    """
    Apply temporal watermarking by modifying time domain
    
    Args:
        audio: Input audio array
        watermark_text: Text to embed
        
    Returns:
        Watermarked audio array
    """
    # Create a very subtle temporal pattern
    watermark_hash = hash(watermark_text) % 1000
    pattern_length = len(audio) // 100
    
    # Generate watermark pattern
    pattern = np.sin(np.linspace(0, 2 * np.pi * watermark_hash, pattern_length))
    pattern *= 0.0001  # Very low amplitude
    
    # Apply pattern at regular intervals
    watermarked_audio = audio.copy()
    for i in range(0, len(audio) - pattern_length, len(audio) // 10):
        watermarked_audio[i:i+pattern_length] += pattern
    
    return watermarked_audio

def detect_watermark(audio_path: str, expected_watermark: str = None) -> dict:
    """
    Attempt to detect watermark in audio file
    
    Args:
        audio_path: Path to audio file to analyze
        expected_watermark: Expected watermark text (if known)
        
    Returns:
        Dictionary with detection results
    """
    try:
        # Load audio
        audio, sr = librosa.load(audio_path, sr=None)
        
        # Try to read metadata
        info = sf.info(audio_path)
        
        result = {
            "metadata_found": True,
            "file_info": {
                "duration": len(audio) / sr,
                "sample_rate": sr,
                "channels": 1 if audio.ndim == 1 else audio.shape[1]
            }
        }
        
        if expected_watermark:
            result["expected_watermark"] = expected_watermark
            # Simple check for expected patterns
            result["watermark_detected"] = _check_for_pattern(audio, expected_watermark)
        
        return result
        
    except Exception as e:
        return {"error": str(e)}

def _check_for_pattern(audio: np.ndarray, watermark_text: str) -> bool:
    """
    Simple pattern detection for watermark
    
    Args:
        audio: Audio array
        watermark_text: Watermark text to check for
        
    Returns:
        Boolean indicating if pattern might be present
    """
    # This is a simplified detection - in practice, this would be more sophisticated
    watermark_hash = hash(watermark_text) % 1000
    
    # Analyze spectral characteristics
    stft = librosa.stft(audio)
    magnitude = np.abs(stft)
    
    # Look for patterns that might indicate our watermark
    # This is a very basic implementation
    pattern_strength = np.std(magnitude) / np.mean(magnitude)
    
    # Arbitrary threshold - in practice, this would be calibrated
    return pattern_strength > 0.1

def remove_watermark(audio_path: str, output_path: str, method: str = "denoise") -> str:
    """
    Attempt to remove or reduce watermark from audio
    
    Args:
        audio_path: Path to watermarked audio
        output_path: Path to save cleaned audio
        method: Removal method ("denoise", "filter")
        
    Returns:
        Path to cleaned audio file
    """
    # Load audio
    audio, sr = librosa.load(audio_path, sr=None)
    
    if method == "denoise":
        # Simple denoising approach
        cleaned_audio = _denoise_audio(audio)
    elif method == "filter":
        # Frequency filtering approach
        cleaned_audio = _filter_audio(audio, sr)
    else:
        raise ValueError(f"Unknown removal method: {method}")
    
    # Save cleaned audio
    sf.write(output_path, cleaned_audio, sr)
    print(f"Cleaned audio saved to: {output_path}")
    
    return output_path

def _denoise_audio(audio: np.ndarray) -> np.ndarray:
    """Simple denoising using spectral subtraction"""
    # Convert to frequency domain
    stft = librosa.stft(audio)
    magnitude = np.abs(stft)
    phase = np.angle(stft)
    
    # Estimate noise (using first few frames)
    noise_frames = 5
    noise_estimate = np.mean(magnitude[:, :noise_frames], axis=1, keepdims=True)
    
    # Spectral subtraction
    alpha = 2.0  # Over-subtraction factor
    cleaned_magnitude = magnitude - alpha * noise_estimate
    cleaned_magnitude = np.maximum(cleaned_magnitude, 0.1 * magnitude)  # Floor
    
    # Reconstruct
    cleaned_stft = cleaned_magnitude * np.exp(1j * phase)
    cleaned_audio = librosa.istft(cleaned_stft)
    
    return cleaned_audio

def _filter_audio(audio: np.ndarray, sr: int) -> np.ndarray:
    """Apply frequency filtering to remove potential watermarks"""
    # Simple high-pass filter to remove very low frequency artifacts
    from scipy import signal
    
    # Design high-pass filter
    nyquist = sr / 2
    cutoff = 80  # Hz
    sos = signal.butter(4, cutoff / nyquist, btype='high', output='sos')
    
    # Apply filter
    filtered_audio = signal.sosfilt(sos, audio)
    
    return filtered_audio 