# üöÄ Voice Cloning API - Quick Start Guide

Configuraci√≥n optimizada para m√°ximo rendimiento en puerto **7860** con perfil de voz "**voices**" preconfigurado.

## ‚ö° Inicio R√°pido

### 1. Iniciar el Servidor (Configuraci√≥n Optimizada)
```bash
# Inicio optimizado con configuraci√≥n autom√°tica
python quick_start.py

# O con el script est√°ndar pero optimizado
python start_voice_api.py --production --cache-size 6144 --max-concurrent 3
```

### 2. Verificar que Todo Funciona
```bash
# Verificar estado de la API
python voice_commands.py status

# Listar voces disponibles
python voice_commands.py voices
```

### 3. Prueba B√°sica
```bash
# Clonar voz con el perfil preconfigurado "voices"
python voice_commands.py clone "Hola, esta es una prueba de clonaci√≥n de voz"

# Con configuraci√≥n personalizada
python voice_commands.py clone "Texto a sintetizar" --voice voices --temperature 0.8
```

## üé≠ Tu Configuraci√≥n Actual

### Audio de Referencia
- **Archivo**: `Ah, ¬øen serio? Vaya, eso debe ser un poco inc√≥modo para tu equipo..mp3`
- **Transcripci√≥n**: "Ah, ¬øen serio? Vaya, eso debe ser un poco inc√≥modo para tu equipo."
- **Perfil**: `voices` (configurado autom√°ticamente)

### Configuraci√≥n del Servidor
- **Puerto**: 7860
- **Cache**: 6GB (optimizado para rendimiento)
- **Requests concurrentes**: 3
- **Chunking adaptativo**: Habilitado
- **Optimizaci√≥n GPU**: Habilitada
- **Modo producci√≥n**: Activado

## üìù Comandos Esenciales

### Usar Voice Cloning
```bash
# B√°sico con perfil "voices"
python voice_commands.py clone "Tu texto aqu√≠"

# Con streaming (tiempo real)
python voice_commands.py clone "Tu texto aqu√≠" --stream

# Con temperatura personalizada
python voice_commands.py clone "Tu texto aqu√≠" --temperature 0.8

# Guardar en archivo espec√≠fico
python voice_commands.py clone "Tu texto aqu√≠" --output mi_audio.wav
```

### Gestionar Voces
```bash
# Ver voces disponibles
python voice_commands.py voices

# Agregar nueva voz (ej: "fran")
python voice_commands.py add fran "ruta/a/audio_fran.mp3" "Transcripci√≥n del audio de Fran"

# Usar la nueva voz
python voice_commands.py clone "Texto con voz de Fran" --voice fran
```

### Monitoreo
```bash
# Estado del sistema
python voice_commands.py status

# Prueba completa
python test_voices_api.py

# Prueba r√°pida
python test_voices_api.py --quick
```

## üåê URLs Importantes

- **API Base**: http://localhost:7860
- **Health Check**: http://localhost:7860/health
- **Documentaci√≥n API**: http://localhost:7860/docs
- **Voice Profiles**: http://localhost:7860/voices
- **Performance Stats**: http://localhost:7860/performance-stats

## üî• Ejemplos Avanzados

### Clonaci√≥n con cURL
```bash
# Usando el perfil "voices"
curl -X POST "http://localhost:7860/clone-voice" \
     -F "text=Hola mundo desde la API optimizada" \
     -F "voice_name=voices" \
     -F "temperature=0.7" \
     -F "remove_silence=true"

# Streaming
curl -X POST "https://i251u0bgdxqzvq-7860.proxy.runpod.net/clone-voice-stream" \
     -F "text=Prueba de streaming" \
     -F "voice_name=voices" \
     -F "streaming=true" \
     --output stream_test.wav
```

### Con Python (Async)
```python
import asyncio
import aiohttp

async def clone_voice():
    async with aiohttp.ClientSession() as session:
        data = aiohttp.FormData()
        data.add_field('text', 'Tu texto aqu√≠')
        data.add_field('voice_name', 'voices')
        data.add_field('temperature', '0.7')
        
        async with session.post('http://localhost:7860/clone-voice', data=data) as resp:
            result = await resp.json()
            print(f"Audio generado: {result['audio_url']}")

asyncio.run(clone_voice())
```

## üéØ Optimizaciones Aplicadas

### GPU
- ‚úÖ Memoria GPU optimizada (85% del total)
- ‚úÖ Precision mixta habilitada
- ‚úÖ Cache de memoria GPU
- ‚úÖ Garbage collection autom√°tico

### Procesamiento
- ‚úÖ Chunking adaptativo basado en carga del sistema
- ‚úÖ Cache LRU para audio de referencia (6GB)
- ‚úÖ Paralelizaci√≥n de audio preprocessing
- ‚úÖ Eliminaci√≥n de silencios optimizada

### Red
- ‚úÖ Streaming chunkeado para baja latencia
- ‚úÖ Compresi√≥n autom√°tica de respuestas
- ‚úÖ M√°ximo 3 requests concurrentes
- ‚úÖ Timeout optimizados

## üìä M√©tricas de Performance

La API reporta estas m√©tricas en tiempo real:

- **Realtime Factor**: Tiempo de procesamiento vs duraci√≥n del audio
- **Tokens/Second**: Velocidad de procesamiento de texto
- **Memory Usage**: RAM y GPU en tiempo real
- **Cache Hit Ratio**: Eficiencia del cache de audio
- **System Load**: Carga del sistema para chunking adaptativo

### Ver M√©tricas
```bash
# M√©tricas del sistema
curl http://localhost:7860/performance-stats | jq

# Recomendaci√≥n de chunk size
curl "http://localhost:7860/chunk-size-recommendation?text=Tu%20texto&streaming=false"
```

## üîß Troubleshooting

### Problemas Comunes

**API no responde**
```bash
# Verificar que el puerto 7860 est√© libre
lsof -i :7860

# Reiniciar con logs detallados
python quick_start.py
```

**Audio de referencia no encontrado**
```bash
# Verificar que el archivo existe
ls -la "Ah, ¬øen serio? Vaya, eso debe ser un poco inc√≥modo para tu equipo..mp3"

# Re-configurar voice profiles
python voice_commands.py add voices "tu_audio.mp3" "transcripci√≥n"
```

**Performance lento**
```bash
# Verificar GPU
python -c "import torch; print(torch.cuda.is_available())"

# Limpiar cache si est√° lleno
curl -X POST http://localhost:7860/clear-cache

# Ajustar configuraci√≥n
python start_voice_api.py --cache-size 2048 --max-concurrent 1
```

## üöÄ Pr√≥ximos Pasos

### Agregar M√°s Voces
```bash
# Ejemplo: agregar voz "fran"
python voice_commands.py add fran "audio_fran.mp3" "Transcripci√≥n exacta del audio"

# Usar la nueva voz
python voice_commands.py clone "Hola desde Fran" --voice fran
```

### Integraci√≥n en Aplicaciones
- Ver `voice_cloning_client.py` para ejemplos de integraci√≥n
- Usar `/docs` para explorar la API interactivamente
- Implementar retry logic para requests concurrentes

### Optimizaciones Adicionales
- Aumentar cache size si tienes m√°s RAM: `--cache-size 8192`
- Ajustar concurrent requests seg√∫n tu GPU: `--max-concurrent 4`
- Usar chunking manual para textos muy largos

---

**üé§ ¬°Disfruta de la clonaci√≥n de voz optimizada en el puerto 7860!**

Para soporte adicional, revisa los logs en `voice_api.log` o ejecuta las pruebas completas con `python test_voices_api.py`. 