#!/usr/bin/env python3
"""
Script completo para CSM TTS usando sesame/csm-1b + adaptador Elise
Genera audio con expresiones emocionales usando el modelo base descargado
"""
import os
import torch
import json
from pathlib import Path
from transformers import AutoTokenizer, AutoProcessor, CsmForConditionalGeneration
from peft import PeftModel, PeftConfig
import torchaudio
import time

# Configurar variables de entorno
os.environ["NO_TORCH_COMPILE"] = "1"
os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"

def load_csm_with_elise_local():
    """Cargar modelo CSM local con adaptador Elise"""
    print("üîÑ CARGANDO MODELO CSM COMPLETO CON ADAPTADOR ELISE")
    print("=" * 70)
    
    base_model_path = "/workspace/runPodtts/models/sesame-csm-1b"
    adapter_path = "/workspace/runPodtts/models/csm-1b-elise"
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    try:
        print(f"üì• Cargando modelo base desde: {base_model_path}")
        
        # Cargar tokenizer y procesador desde el modelo base local
        tokenizer = AutoTokenizer.from_pretrained(base_model_path)
        print("‚úÖ Tokenizer cargado desde modelo base local")
        
        processor = AutoProcessor.from_pretrained(base_model_path)
        print("‚úÖ Procesador cargado desde modelo base local")
        
        # Cargar modelo base con configuraci√≥n optimizada para A100
        print("üî• Cargando modelo CSM en GPU...")
        base_model = CsmForConditionalGeneration.from_pretrained(
            base_model_path,
            device_map="auto",
            torch_dtype=torch.float16,
            trust_remote_code=True,
            use_safetensors=True
        )
        print("‚úÖ Modelo base CSM cargado")
        
        # Cargar adaptador PEFT Elise
        print("üé≠ Aplicando adaptador Elise...")
        model = PeftModel.from_pretrained(base_model, adapter_path)
        print("‚úÖ Adaptador Elise aplicado exitosamente")
        
        # Informaci√≥n del modelo
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"\nüìä INFORMACI√ìN DEL MODELO:")
        print(f"üî¢ Par√°metros totales: {total_params:,}")
        print(f"üéØ Par√°metros entrenables: {trainable_params:,}")
        print(f"üìà % Entrenables: {100 * trainable_params / total_params:.2f}%")
        print(f"üéØ Device final: {next(model.parameters()).device}")
        
        return model, processor, tokenizer
        
    except Exception as e:
        print(f"‚ùå Error cargando modelo: {e}")
        import traceback
        traceback.print_exc()
        return None, None, None

def create_comprehensive_emotional_prompts():
    """Crear un conjunto completo de prompts emocionales para prueba"""
    return [
        # Saludos y presentaciones
        {
            "text": "Hello! I'm Elise, your emotional AI companion. How are you feeling today?",
            "description": "Saludo c√°lido y emp√°tico",
            "filename": "01_warm_greeting",
            "category": "greeting"
        },
        
        # Expresiones de alegr√≠a
        {
            "text": "That's absolutely wonderful! <laughs> I'm so happy to hear that news!",
            "description": "Alegr√≠a genuina con risa",
            "filename": "02_joyful_laughter",
            "category": "joy"
        },
        {
            "text": "Oh my goodness! <giggles> You always know how to make me smile!",
            "description": "Risita divertida y cari√±osa",
            "filename": "03_affectionate_giggles",
            "category": "joy"
        },
        
        # Expresiones de tristeza y cansancio
        {
            "text": "I understand how you feel. <sighs> Sometimes life can be really challenging.",
            "description": "Empat√≠a con suspiro comprensivo",
            "filename": "04_empathetic_sigh",
            "category": "empathy"
        },
        {
            "text": "<sadly> I'm sorry to hear you're going through a difficult time. I'm here for you.",
            "description": "Expresi√≥n triste pero solidaria",
            "filename": "05_compassionate_sadness",
            "category": "comfort"
        },
        
        # Expresiones de sorpresa
        {
            "text": "Wait, what?! <gasps> That's incredible! Tell me more!",
            "description": "Sorpresa y entusiasmo",
            "filename": "06_surprised_gasp",
            "category": "surprise"
        },
        {
            "text": "Oh wow! <gasps> I never expected that! <laughs> This is amazing!",
            "description": "Sorpresa que se convierte en alegr√≠a",
            "filename": "07_surprise_to_joy",
            "category": "surprise"
        },
        
        # Susurros y confidencias
        {
            "text": "<whispers> Can I tell you a secret? I think you're absolutely wonderful.",
            "description": "Susurro √≠ntimo y cari√±oso",
            "filename": "08_intimate_whisper",
            "category": "intimate"
        },
        {
            "text": "<whispers> Come closer, I have something important to share with you.",
            "description": "Susurro misterioso y atractivo",
            "filename": "09_mysterious_whisper",
            "category": "intimate"
        },
        
        # Narrativas con m√∫ltiples emociones
        {
            "text": "Let me tell you about my day! <laughs> So I was learning something new, and suddenly <gasps> everything just clicked! <giggles> It was such an amazing moment!",
            "description": "Historia con transiciones emocionales",
            "filename": "10_emotional_story",
            "category": "narrative"
        },
        
        # Expresiones de apoyo
        {
            "text": "You know what? <sighs> Even when things get tough, you always find a way to keep going. That's really inspiring.",
            "description": "Apoyo reflexivo y motivador",
            "filename": "11_supportive_reflection",
            "category": "support"
        },
        
        # Expresiones juguetonas
        {
            "text": "Welcome to our magical conversation! <giggles> Here, we can explore any topic and have the most wonderful discussions!",
            "description": "Bienvenida juguetona y m√°gica",
            "filename": "12_playful_welcome",
            "category": "playful"
        }
    ]

def generate_emotional_audio_complete(model, processor, tokenizer, prompts):
    """Generar archivos de audio completos con expresiones emocionales"""
    print("\nüéµ GENERANDO AUDIO COMPLETO CON EXPRESIONES EMOCIONALES")
    print("=" * 70)
    
    output_dir = Path("/workspace/runPodtts/outputs/elise_complete_audio")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    device = next(model.parameters()).device
    results = []
    
    print(f"üéØ Generando en device: {device}")
    print(f"üî• Modelo dtype: {next(model.parameters()).dtype}")
    
    for i, prompt in enumerate(prompts):
        print(f"\nüé≠ [{i+1:2d}/{len(prompts)}] {prompt['description']}")
        print(f"üìÅ Categor√≠a: {prompt['category']}")
        print(f"üí¨ Texto: {prompt['text']}")
        
        try:
            # Formatear texto para speaker 0 (Elise)
            formatted_text = f"[0]{prompt['text']}"
            
            # Tokenizar con configuraci√≥n espec√≠fica para CSM
            inputs = tokenizer(
                formatted_text, 
                return_tensors="pt", 
                add_special_tokens=True,
                padding=True,
                truncation=True,
                max_length=512
            ).to(device)
            
            print(f"üî¢ Tokens de entrada: {inputs['input_ids'].shape[1]}")
            
            # Generar audio con par√°metros optimizados
            start_time = time.time()
            
            with torch.no_grad():
                # Configuraci√≥n optimizada para CSM + Elise
                generation_config = {
                    "max_new_tokens": 750,  # M√°s tokens para frases complejas
                    "do_sample": True,
                    "temperature": 0.8,     # Ligeramente m√°s creativo para emociones
                    "top_p": 0.9,
                    "top_k": 50,
                    "pad_token_id": tokenizer.pad_token_id,
                    "eos_token_id": tokenizer.eos_token_id,
                    "use_cache": True
                }
                
                # Generar tokens y audio
                outputs = model.generate(
                    **inputs,
                    **generation_config
                )
            
            generation_time = time.time() - start_time
            print(f"‚è±Ô∏è  Tiempo de generaci√≥n: {generation_time:.2f}s")
            print(f"üî¢ Tokens generados: {outputs.shape[1] - inputs['input_ids'].shape[1]}")
            
            # Procesar outputs para extraer audio
            try:
                # Intentar extraer audio usando el procesador
                audio_data = processor.decode_audio(outputs)
                
                if audio_data is not None:
                    output_path = output_dir / f"{prompt['filename']}.wav"
                    
                    # Procesar formato del audio
                    if isinstance(audio_data, torch.Tensor):
                        if audio_data.dim() == 3:  # [batch, channels, samples]
                            audio_data = audio_data.squeeze(0)
                        elif audio_data.dim() == 1:  # [samples]
                            audio_data = audio_data.unsqueeze(0)  # [1, samples]
                    
                    # Guardar audio
                    sample_rate = 24000  # CSM usa 24kHz
                    torchaudio.save(
                        str(output_path), 
                        audio_data.cpu().float(), 
                        sample_rate=sample_rate
                    )
                    
                    duration = audio_data.shape[-1] / sample_rate
                    print(f"‚úÖ Audio guardado: {output_path}")
                    print(f"üìä Duraci√≥n: {duration:.2f}s")
                    print(f"üéµ Sample rate: {sample_rate}Hz")
                    
                    results.append({
                        "prompt": prompt,
                        "output_path": str(output_path),
                        "generation_time": generation_time,
                        "duration": duration,
                        "sample_rate": sample_rate,
                        "success": True
                    })
                else:
                    print("‚ùå No se pudo extraer audio del modelo")
                    results.append({
                        "prompt": prompt,
                        "output_path": None,
                        "generation_time": generation_time,
                        "duration": 0,
                        "success": False,
                        "error": "Audio extraction failed"
                    })
                    
            except Exception as audio_error:
                print(f"‚ùå Error procesando audio: {audio_error}")
                results.append({
                    "prompt": prompt,
                    "output_path": None,
                    "generation_time": generation_time,
                    "duration": 0,
                    "success": False,
                    "error": str(audio_error)
                })
                
        except Exception as e:
            print(f"‚ùå Error en generaci√≥n: {e}")
            import traceback
            traceback.print_exc()
            results.append({
                "prompt": prompt,
                "output_path": None,
                "generation_time": 0,
                "duration": 0,
                "success": False,
                "error": str(e)
            })
    
    return results, output_dir

def save_comprehensive_report(results, output_dir):
    """Guardar reporte completo de generaci√≥n"""
    report_path = output_dir / "comprehensive_generation_report.json"
    
    # Calcular estad√≠sticas por categor√≠a
    categories = {}
    for result in results:
        cat = result["prompt"]["category"]
        if cat not in categories:
            categories[cat] = {"total": 0, "successful": 0, "failed": 0, "total_duration": 0}
        
        categories[cat]["total"] += 1
        if result["success"]:
            categories[cat]["successful"] += 1
            categories[cat]["total_duration"] += result["duration"]
        else:
            categories[cat]["failed"] += 1
    
    report = {
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "model_info": {
            "base_model": "sesame/csm-1b",
            "adapter": "therealcyberlord/csm-1b-elise",
            "speaker_id": 0,
            "device": str(next(iter(results))["prompt"].get("device", "cuda")),
            "dtype": "float16"
        },
        "global_statistics": {
            "total_prompts": len(results),
            "successful": sum(1 for r in results if r["success"]),
            "failed": sum(1 for r in results if not r["success"]),
            "success_rate": f"{100 * sum(1 for r in results if r['success']) / len(results):.1f}%",
            "total_generation_time": sum(r["generation_time"] for r in results),
            "total_audio_duration": sum(r["duration"] for r in results if r["success"]),
            "avg_generation_time": sum(r["generation_time"] for r in results) / len(results),
            "categories": list(categories.keys())
        },
        "category_statistics": categories,
        "detailed_results": results
    }
    
    with open(report_path, "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"\nüìä REPORTE COMPLETO DE GENERACI√ìN:")
    print(f"‚úÖ Exitosos: {report['global_statistics']['successful']}/{report['global_statistics']['total_prompts']} ({report['global_statistics']['success_rate']})")
    print(f"‚ùå Fallidos: {report['global_statistics']['failed']}/{report['global_statistics']['total_prompts']}")
    print(f"‚è±Ô∏è  Tiempo total: {report['global_statistics']['total_generation_time']:.2f}s")
    print(f"üéµ Audio total: {report['global_statistics']['total_audio_duration']:.2f}s")
    print(f"üìà Tiempo promedio: {report['global_statistics']['avg_generation_time']:.2f}s por muestra")
    
    print(f"\nüìã ESTAD√çSTICAS POR CATEGOR√çA:")
    for cat, stats in categories.items():
        success_rate = 100 * stats["successful"] / stats["total"] if stats["total"] > 0 else 0
        print(f"  üé≠ {cat}: {stats['successful']}/{stats['total']} ({success_rate:.1f}%) - {stats['total_duration']:.1f}s")
    
    print(f"\nüìÑ Reporte detallado guardado: {report_path}")

def main():
    """Funci√≥n principal"""
    print("üöÄ INICIANDO CSM TTS COMPLETO CON MODELO ELISE")
    print("=" * 80)
    
    # Verificar CUDA y recursos
    if torch.cuda.is_available():
        print(f"‚úÖ CUDA disponible: {torch.cuda.get_device_name()}")
        print(f"üî• VRAM disponible: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
        print(f"üíæ VRAM libre: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated()) / 1e9:.1f} GB")
    else:
        print("‚ö†Ô∏è  CUDA no disponible, usando CPU")
    
    # Cargar modelo completo
    model, processor, tokenizer = load_csm_with_elise_local()
    
    if model is None:
        print("‚ùå No se pudo cargar el modelo. Terminando.")
        return False
    
    # Crear prompts emocionales completos
    prompts = create_comprehensive_emotional_prompts()
    print(f"\nüìù Preparados {len(prompts)} prompts emocionales en {len(set(p['category'] for p in prompts))} categor√≠as")
    
    # Mostrar categor√≠as
    categories = {}
    for p in prompts:
        cat = p['category']
        categories[cat] = categories.get(cat, 0) + 1
    
    print("üé≠ Categor√≠as emocionales:")
    for cat, count in categories.items():
        print(f"   ‚Ä¢ {cat}: {count} prompts")
    
    # Generar audio completo
    print(f"\nüéµ Iniciando generaci√≥n de audio...")
    results, output_dir = generate_emotional_audio_complete(model, processor, tokenizer, prompts)
    
    # Guardar reporte completo
    save_comprehensive_report(results, output_dir)
    
    print("\nüéâ GENERACI√ìN COMPLETA FINALIZADA")
    print("=" * 80)
    print(f"üìÅ Archivos de audio en: {output_dir}")
    print("üéß Reproduce los archivos para escuchar a Elise con expresiones emocionales")
    print("üé≠ Elise puede expresar: alegr√≠a, tristeza, sorpresa, susurros, narrativas y m√°s!")
    print("\nüí° PR√ìXIMOS PASOS:")
    print("   ‚Ä¢ Escucha los archivos generados")
    print("   ‚Ä¢ Experimenta con nuevos prompts emocionales")
    print("   ‚Ä¢ Ajusta par√°metros de generaci√≥n seg√∫n preferencias")
    print("   ‚Ä¢ Usa Elise para proyectos de voice cloning emocional")
    
    return True

if __name__ == "__main__":
    main() 