#!/usr/bin/env python3
"""
Test script para CSM usando la implementaci√≥n nativa de Hugging Face Transformers
"""
import torch
from transformers import CsmForConditionalGeneration, AutoProcessor
import os

# Configurar variable de entorno
os.environ["NO_TORCH_COMPILE"] = "1"

def test_csm_basic():
    """Test b√°sico del modelo CSM con generaci√≥n simple"""
    print("üéØ Iniciando test de CSM con Transformers...")
    
    model_id = "sesame/csm-1b"
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    print(f"üî• Usando device: {device}")
    
    try:
        # Cargar modelo y procesador
        print("üì• Cargando modelo y procesador...")
        processor = AutoProcessor.from_pretrained(model_id)
        model = CsmForConditionalGeneration.from_pretrained(
            model_id, 
            device_map=device,
            torch_dtype=torch.float16 if device == "cuda" else torch.float32
        )
        
        print("‚úÖ Modelo cargado exitosamente!")
        
        # Generar audio simple sin contexto
        print("üé≠ Generando audio: 'Hello from Sesame CSM in Spanish: Hola desde Sesame!'")
        text = "[0]Hello from Sesame CSM in Spanish: Hola desde Sesame!"
        inputs = processor(text, add_special_tokens=True).to(device)
        
        # Generar audio
        with torch.no_grad():
            audio = model.generate(**inputs, output_audio=True, max_new_tokens=250)
        
        # Guardar audio
        output_path = "/workspace/runPodtts/outputs/test_basic_csm.wav"
        processor.save_audio(audio, output_path)
        print(f"üéµ Audio guardado en: {output_path}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error en test b√°sico: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_csm_conversation():
    """Test con conversaci√≥n usando formato de chat"""
    print("\nüé≠ Test de conversaci√≥n...")
    
    model_id = "sesame/csm-1b"
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    try:
        processor = AutoProcessor.from_pretrained(model_id)
        model = CsmForConditionalGeneration.from_pretrained(
            model_id, 
            device_map=device,
            torch_dtype=torch.float16 if device == "cuda" else torch.float32
        )
        
        # Crear conversaci√≥n de ejemplo
        conversation = [
            {"role": "0", "content": [{"type": "text", "text": "Hello! How are you today?"}]},
            {"role": "1", "content": [{"type": "text", "text": "I'm doing great, thank you!"}]},
            {"role": "0", "content": [{"type": "text", "text": "That's wonderful to hear!"}]},
        ]
        
        print("üí¨ Generando conversaci√≥n...")
        inputs = processor.apply_chat_template(
            conversation,
            tokenize=True,
            return_dict=True,
        ).to(device)
        
        # Generar audio
        with torch.no_grad():
            audio = model.generate(**inputs, output_audio=True, max_new_tokens=300)
        
        # Guardar audio
        output_path = "/workspace/runPodtts/outputs/test_conversation_csm.wav"
        processor.save_audio(audio, output_path)
        print(f"üéµ Conversaci√≥n guardada en: {output_path}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error en test de conversaci√≥n: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    print("üöÄ INICIANDO TESTS DE CSM TTS")
    print("=" * 50)
    
    # Verificar CUDA
    if torch.cuda.is_available():
        print(f"‚úÖ CUDA disponible: {torch.cuda.get_device_name()}")
        print(f"üî• VRAM disponible: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    else:
        print("‚ö†Ô∏è  CUDA no disponible, usando CPU")
    
    # Crear directorio de salida
    os.makedirs("/workspace/runPodtts/outputs", exist_ok=True)
    
    # Ejecutar tests
    success_basic = test_csm_basic()
    success_conversation = test_csm_conversation()
    
    print("\nüìä RESUMEN DE TESTS:")
    print(f"Test b√°sico: {'‚úÖ EXITOSO' if success_basic else '‚ùå FALLIDO'}")
    print(f"Test conversaci√≥n: {'‚úÖ EXITOSO' if success_conversation else '‚ùå FALLIDO'}")
    
    if success_basic and success_conversation:
        print("\nüéâ ¬°Todos los tests pasaron! CSM est√° funcionando correctamente.")
        return True
    else:
        print("\n‚ö†Ô∏è  Algunos tests fallaron. Revisar los errores arriba.")
        return False

if __name__ == "__main__":
    main() 